# NumerusX - AI Agent API Integration (Google Gemini 2.5 Flash Preview) üß†‚ö°

**Objectif**: Int√©grer l'API Google Gemini 2.5 Flash Preview comme moteur de d√©cision principal pour l'`AIAgent` de NumerusX. Ce plan met l'accent sur une int√©gration efficace, une optimisation des co√ªts en minimisant les appels API par une pr√©paration minutieuse des donn√©es, et une interaction utilisateur claire concernant les d√©cisions de l'IA.

## Pr√©requis
* Un compte Google Cloud avec l'API Gemini activ√©e et une cl√© API
* Compr√©hension de l'architecture de NumerusX et du r√¥le de `AIAgent`

## Mod√®le d'IA S√©lectionn√©
* **API**: Google AI (via google-generativeai)
* **Mod√®le**: `gemini-2.5-flash-preview-05-20` (d√©fini dans `Config.GEMINI_MODEL_NAME`)

## Phase 1: Configuration et Installation ‚úÖ COMPL√âT√â

### T√¢che 1.1: Configuration ‚úÖ
-   [x] `GOOGLE_API_KEY` ajout√© √† `Config` avec chiffrement
-   [x] `GEMINI_MODEL_NAME = "gemini-2.5-flash-preview-05-20"` dans `Config`
-   [x] `GEMINI_API_TIMEOUT_SECONDS = 30` dans `Config`
-   [x] `GEMINI_MAX_TOKENS_INPUT = 4096` dans `Config`
-   [x] Cl√© API prot√©g√©e via `.env` et `EncryptionUtil`

### T√¢che 1.2: D√©pendances ‚úÖ
-   [x] `google-generativeai>=0.5.4` ajout√© √† `requirements.txt`

## Phase 2: Client API Gemini ‚úÖ COMPL√âT√â

### T√¢che 2.1: GeminiClient ‚úÖ
-   [x] Fichier `app/ai_agent/gemini_client.py` cr√©√©
-   [x] Classe `GeminiClient` impl√©ment√©e avec :
    -   [x] Initialisation avec `GenerativeModel`
    -   [x] Configuration `safety_settings` et `generation_config`
    -   [x] M√©thode `get_decision` asynchrone
    -   [x] Gestion timeout et extraction metadata
    -   [x] Section test `__main__`

### T√¢che 2.2: Gestion des Erreurs ‚úÖ
-   [x] Import `google.api_core.exceptions`
-   [x] Gestion exceptions sp√©cifiques :
    -   [x] `asyncio.TimeoutError`
    -   [x] `InvalidArgument`, `ResourceExhausted`, `PermissionDenied`
    -   [x] `ServiceUnavailable`, `InternalServerError`
    -   [x] `BlockedPromptException`, `StopCandidateException`
-   [x] V√©rification `prompt_feedback.block_reason`
-   [x] Format retour `{'success': False, 'error': ..., 'data': ...}`
-   [x] Logging appropri√© des erreurs

### T√¢che 2.3: Tests GeminiClient ‚ö†Ô∏è √Ä FAIRE
- [ ] Cr√©er `tests/test_gemini_client.py` :
    - [ ] Test initialisation avec cl√© valide/invalide
    - [ ] Test appel `get_decision` avec prompt simple
    - [ ] Test gestion timeout (mock asyncio.sleep)
    - [ ] Test erreurs API (mock exceptions Google)
    - [ ] Test calcul co√ªt avec `usage_metadata`
    - [ ] Validation format r√©ponse `{'success': ..., 'data': ...}`
    - [ ] Test blocage contenu (mock BlockedPromptException)

## Phase 3: Int√©gration AIAgent et Optimisation ‚ö†Ô∏è EN COURS

### T√¢che 3.1: Int√©gration AIAgent ‚úÖ PARTIELLEMENT
-   [x] `GeminiClient` import√© et initialis√© dans `AIAgent`
-   [x] M√©thode `decide_trade` devenue asynchrone
-   [x] Appel `await self.gemini_client.get_decision(prompt_text)`
-   [x] Gestion √©chec API -> retour HOLD par d√©faut
-   [ ] Construction prompt optimis√© (placeholder actuel)
-   [ ] Parsing robuste r√©ponse JSON (placeholder actuel)

### T√¢che 3.1.5: Structure AggregatedInputs ‚ö†Ô∏è URGENT
- [ ] **Cr√©er `app/models/ai_inputs.py`** :
    - [ ] Mod√®les Pydantic pour chaque source :
        ```python
        from pydantic import BaseModel, Field, confloat, constr
        from typing import List, Optional, Dict, Literal
        from datetime import datetime
        
        class MarketDataInput(BaseModel):
            current_price: float
            recent_ohlcv_1h: List[Dict]
            liquidity_depth_usd: float
            recent_trend_1h: Literal["UPWARD", "DOWNWARD", "SIDEWAYS"]
            key_support_resistance: Dict[str, float]
            volatility_1h_atr_percentage: float
        
        class SignalSourceInput(BaseModel):
            source_name: str
            signal: Literal["STRONG_BUY", "BUY", "NEUTRAL", "SELL", "STRONG_SELL"]
            confidence: confloat(ge=0, le=1)
            indicators: Dict[str, Any]
            reasoning_snippet: constr(max_length=200)
        
        class PredictionEngineInput(BaseModel):
            price_prediction_4h: Dict
            market_regime_1h: str
            sentiment_analysis: Dict
        
        class RiskManagerInput(BaseModel):
            max_exposure_per_trade_percentage: float
            current_portfolio_value_usd: float
            available_capital_usdc: float
            max_trade_size_usd: float
            overall_portfolio_risk_level: Literal["LOW", "MODERATE", "HIGH"]
        
        class SecurityCheckerInput(BaseModel):
            token_security_score: confloat(ge=0, le=1)
            recent_security_alerts: List[str]
        
        class PortfolioManagerInput(BaseModel):
            current_positions: List[Dict]
            total_pnl_realized_24h_usd: float
        
        class AggregatedInputs(BaseModel):
            timestamp_utc: datetime
            target_pair: Dict[str, str]
            market_data: MarketDataInput
            signal_sources: List[SignalSourceInput]
            prediction_engine_outputs: PredictionEngineInput
            risk_manager_inputs: RiskManagerInput
            portfolio_manager_inputs: PortfolioManagerInput
            security_checker_inputs: SecurityCheckerInput
        ```
    - [ ] M√©thodes de validation custom si n√©cessaire
    - [ ] Documentation des champs

### T√¢che 3.2: Prompt Optimis√© ‚ö†Ô∏è √Ä FAIRE
- [ ] Construire prompt structur√© dans `AIAgent._build_prompt()` :
    - [ ] Section ROLE (agent trading Solana)
    - [ ] Section MARKET DATA (prix, volume, liquidit√©)
    - [ ] Section TECHNICAL INDICATORS (RSI, MACD, etc.)
    - [ ] Section AI PREDICTIONS (prix, r√©gime, sentiment)
    - [ ] Section RISK PARAMETERS (limites, capital)
    - [ ] Section TOKEN SECURITY (score, alertes)
    - [ ] Instructions format JSON output
    - [ ] Limite tokens avec troncature intelligente

### T√¢che 3.2.5: Optimisation Tokens ‚ö†Ô∏è √Ä FAIRE
- [ ] Impl√©menter compression `aggregated_inputs` :
    - [ ] Fonction `_compress_market_data()` :
        - [ ] OHLCV : garder seulement N derni√®res bougies
        - [ ] Ou calculer stats (min, max, moyenne)
    - [ ] Fonction `_filter_signal_sources()` :
        - [ ] Prioriser par confiance
        - [ ] Limiter √† top N signaux
        - [ ] Concat√©ner reasoning_snippets
    - [ ] Validation taille finale < `GEMINI_MAX_TOKENS_INPUT`
    - [ ] Fallback si trop grand : sections moins prioritaires

### T√¢che 3.3: Parsing R√©ponse ‚ö†Ô∏è √Ä FAIRE
- [ ] Impl√©menter parsing robuste dans `AIAgent` :
    - [ ] Mod√®le Pydantic `TradeDecision` :
        ```python
        class TradeDecision(BaseModel):
            decision: Literal["BUY", "SELL", "HOLD"]
            token_pair: str
            amount_usd: Optional[confloat(gt=0)] = None
            confidence: confloat(ge=0, le=1)
            stop_loss_price: Optional[confloat(gt=0)] = None
            take_profit_price: Optional[confloat(gt=0)] = None
            reasoning: constr(min_length=10, max_length=500)
        ```
    - [ ] Try/except pour JSON malform√©
    - [ ] Retry avec prompt modifi√© si √©chec
    - [ ] Fallback HOLD si parsing impossible

## Phase 4: Journalisation et Robustesse ‚ö†Ô∏è √Ä FAIRE

### T√¢che 4.1: Journalisation Compl√®te
- [ ] Logger dans `GeminiClient` :
    - [ ] Prompt complet (si mode debug)
    - [ ] R√©ponse brute Gemini
    - [ ] Metadata utilisation (tokens in/out)
    - [ ] Temps de r√©ponse API
- [ ] Logger dans `AIAgent` :
    - [ ] D√©cision structur√©e finale
    - [ ] Raisonnement pars√©
    - [ ] Erreurs parsing

### T√¢che 4.2: M√©canismes Fallback
- [ ] Configurer `tenacity` pour retry :
    - [ ] Retry sur `ResourceExhausted`
    - [ ] Retry sur `ServiceUnavailable`
    - [ ] Backoff exponentiel
    - [ ] Max 3 tentatives
- [ ] Strat√©gie fallback principale :
    - [ ] Si √©chec API -> d√©cision HOLD
    - [ ] Raisonnement : "API unavailable, defaulting to safety"
    - [ ] Log critique pour alerte
    - [ ] Pas de fallback vers strat√©gie algo

### T√¢che 4.3: Tests Int√©gration
- [ ] Cr√©er `tests/test_ai_agent_integration.py` :
    - [ ] Test construction prompt complet
    - [ ] Test appel GeminiClient (mock)
    - [ ] Test parsing d√©cisions vari√©es
    - [ ] Test gestion erreurs API
    - [ ] Test fallback HOLD
    - [ ] Test performance (latence)
    - [ ] Sc√©narios avec donn√©es manquantes

## Phase 5: UI et Monitoring ‚ö†Ô∏è √Ä FAIRE

### T√¢che 5.1: Affichage D√©cisions UI
- [ ] Modifier `EnhancedDatabase` :
    - [ ] Utiliser table `ai_decisions` (voir todo/01-todo-database.md)
    - [ ] Stocker prompt, r√©ponse, raisonnement
- [ ] API endpoints (dans `app/api/v1/ai_decisions_routes.py`) :
    - [ ] GET `/api/v1/ai/decisions/history`
    - [ ] GET `/api/v1/ai/decisions/{id}/details`
    - [ ] GET `/api/v1/ai/decisions/stats`
- [ ] Composants React :
    - [ ] Liste d√©cisions avec filtres
    - [ ] D√©tail d√©cision avec inputs/outputs
    - [ ] Graphiques confiance vs performance

### T√¢che 5.2: Monitoring Co√ªts
- [ ] Impl√©menter `_calculate_cost()` dans `GeminiClient` :
    ```python
    # Tarifs indicatifs gemini-2.5-flash (√† v√©rifier)
    INPUT_COST_PER_1K_TOKENS = 0.00035  # $0.35/1M tokens
    OUTPUT_COST_PER_1K_TOKENS = 0.00105  # $1.05/1M tokens
    
    def _calculate_cost(self, usage_metadata):
        input_tokens = usage_metadata.get('prompt_token_count', 0)
        output_tokens = usage_metadata.get('candidates_token_count', 0)
        input_cost = (input_tokens / 1000) * INPUT_COST_PER_1K_TOKENS
        output_cost = (output_tokens / 1000) * OUTPUT_COST_PER_1K_TOKENS
        return input_cost + output_cost
    ```
- [ ] Stocker co√ªts dans `ai_decisions` table
- [ ] Dashboard m√©triques :
    - [ ] Co√ªt par jour/semaine/mois
    - [ ] Tokens moyens par d√©cision
    - [ ] Alertes budget d√©pass√©
- [ ] Config `GEMINI_DAILY_BUDGET_USD` dans Config

## Points d'Attention Critiques

### Gestion Erreurs
* **GeminiClient** retourne `{'success': False, ...}` en cas d'erreur
* **AIAgent** doit g√©rer ce format et fallback HOLD
* **DexBot** doit continuer m√™me si IA √©choue

### Optimisation Prompts
* Respecter limite `GEMINI_MAX_TOKENS_INPUT = 4096`
* Compression intelligente des donn√©es
* Prioriser infos critiques

### S√©curit√©
* Cl√© API jamais dans les logs
* Prompt complet seulement en mode debug
* Sanitizer les inputs utilisateur

### Tests Prioritaires
1. Mock complet API Gemini
2. Sc√©narios edge cases (timeout, blocage)
3. Validation format d√©cisions
4. Performance avec gros inputs

## Ordre d'Impl√©mentation

1. **Imm√©diat** :
   - [ ] Cr√©er `app/models/ai_inputs.py`
   - [ ] Cr√©er `tests/test_gemini_client.py`
   - [ ] Impl√©menter `_build_prompt()` dans AIAgent

2. **Court terme** :
   - [ ] Parser robuste avec Pydantic
   - [ ] Optimisation compression tokens
   - [ ] Tests int√©gration complets

3. **Moyen terme** :
   - [ ] API endpoints d√©cisions
   - [ ] Monitoring co√ªts
   - [ ] Dashboard UI React

## M√©triques de Succ√®s
- [ ] Latence d√©cision < 2s (95 percentile)
- [ ] Taux parsing r√©ussi > 99%
- [ ] Co√ªt par d√©cision < $0.001
- [ ] Uptime API > 99.9%